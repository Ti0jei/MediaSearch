"""
Kino.pub downloader logic (–ø–æ–∏—Å–∫ + —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ + —Å—Ç–∞—Ç—É—Å—ã) + –û–ß–ï–†–ï–î–¨.
–†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ GUI, –Ω–æ –æ—Ç–¥–∞—ë—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å —á–µ—Ä–µ–∑ callback.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤–∏–∂–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ kino_hls.py –∏ UC-–ª–æ–≥–∏–∫—É –∏–∑ uc_driver.py.
"""

import os
import re
import time
import threading
import queue
from typing import Callable, List, Optional, Tuple

from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# –ù–∞—à–∏ –º–æ–¥—É–ª–∏
from kino_hls import download_by_item_url, get_hls_info, start_hls_download
from kino_parser import load_cookies
from uc_driver import (
    _safe_get_driver,
    _check_login,
    _check_login_on,
    login_to_kino,
    DriverPool,
)

KINOPUB_BASE = "https://kino.pub"


# -------------------------------------------------------
# –£—Ç–∏–ª–∏—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
# -------------------------------------------------------
def _log(status_cb: Optional[Callable[[str], None]], msg: str):
    print(msg)
    if status_cb:
        try:
            status_cb(msg)
        except Exception:
            pass


# -------------------------------------------------------
# –°–µ—Ä–∏–∞–ª: —Å–µ–∑–æ–Ω—ã/—ç–ø–∏–∑–æ–¥—ã
# -------------------------------------------------------
def parse_series_episodes(
    series_url: str,
    *,
    driver,
    status_cb=None,
    cancel_event=None,
) -> dict:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–µ—Ä–∏–∞–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      {
        "title": "<–Ω–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Ä–∏–∞–ª–∞>",
        "seasons": {
           1: [{"episode": 1, "url": "https://..."}, ...],
           2: [...]
        }
      }

    –í–∞–∂–Ω–æ: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞/—Å–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω–∞ kino.pub –º–æ–≥—É—Ç –º–µ–Ω—è—Ç—å—Å—è, –ø–æ—ç—Ç–æ–º—É —Ç—É—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ fallback-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π.
    """
    if driver is None:
        raise RuntimeError("parse_series_episodes() —Ç—Ä–µ–±—É–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π driver (UC).")

    from urllib.parse import urljoin, urlsplit, urlunsplit, urlencode, parse_qsl

    def _cancelled() -> bool:
        return bool(getattr(cancel_event, "is_set", lambda: False)())

    def _ensure_abs(u: str) -> str:
        u = (u or "").strip()
        if not u:
            return ""
        if u.startswith("http"):
            return u
        return urljoin(KINOPUB_BASE + "/", u)

    def _series_episode_url(base: str, season: int, episode: int) -> str:
        base = _ensure_abs(base)
        parts = list(urlsplit(base))
        q = dict(parse_qsl(parts[3], keep_blank_values=True))
        q["season"] = str(season)
        q["episode"] = str(episode)
        parts[3] = urlencode(q)
        parts[4] = ""  # fragment
        return urlunsplit(parts)

    def _ensure_cf_solved() -> bool:
        try:
            from kino_hls import (
                _has_challenge,
                _driver_is_suppressed,
                _wait_challenge_solved,
                _solve_cloudflare_in_visible_browser,
            )
        except Exception:
            return True

        try:
            if not _has_challenge(driver):
                return True
        except Exception:
            return True

        _log(status_cb, "üß© –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∑–∞—â–∏—Ç–∞ (Cloudflare) ‚Äî —Ä–µ—à–∏—Ç–µ –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –±—Ä–∞—É–∑–µ—Ä–µ‚Ä¶")

        try:
            if not _driver_is_suppressed(driver):
                _wait_challenge_solved(driver, timeout=90)
                return not _has_challenge(driver)
        except Exception:
            pass

        # suppress-–¥—Ä–∞–π–≤–µ—Ä –Ω–µ –ø–æ–∫–∞–∑–∞—Ç—å: –ø—Ä–æ–±—É–µ–º –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å cookies/refresh
        try:
            load_cookies(driver)
            driver.refresh()
        except Exception:
            pass

        try:
            if not _has_challenge(driver):
                return True
        except Exception:
            return True

        ok = False
        try:
            ok = _solve_cloudflare_in_visible_browser(series_url, status_cb=status_cb, timeout=180)
        except Exception:
            ok = False
        if not ok:
            return False

        try:
            load_cookies(driver)
            driver.refresh()
        except Exception:
            pass

        try:
            return not _has_challenge(driver)
        except Exception:
            return True

    def _extract_title(html: str) -> str:
        soup = BeautifulSoup(html, "html.parser")
        title = ""

        # 1) —Å—Ç–∞—Ä–∞–µ–º—Å—è –≤–∑—è—Ç—å –∏–º–µ–Ω–Ω–æ ¬´—Ä—É—Å—Å–∫–∏–π¬ª –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ H1/–≤–∏–¥–∏–º–æ–≥–æ title
        try:
            h = soup.select_one("h1, .item-title, .page-title, h2, h3")
            if h:
                parts = []
                try:
                    parts = [s for s in list(h.stripped_strings) if s]
                except Exception:
                    parts = []
                if parts:
                    title = str(parts[0]).strip()
                else:
                    title = h.get_text(" ", strip=True)
        except Exception:
            title = ""

        # 2) fallback: og:title
        if not title:
            try:
                meta = soup.select_one("meta[property='og:title']")
                if meta and meta.get("content"):
                    title = str(meta.get("content") or "").strip()
            except Exception:
                title = ""

        title = (title or "").strip()

        # —É–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç—ã —Ç–∏–ø–∞ "‚Äî Kino.pub"
        try:
            title = re.sub(r"\s*[‚Äî-]\s*Kino\.pub.*$", "", title, flags=re.I).strip()
        except Exception:
            pass

        # —É–±–∏—Ä–∞–µ–º –≥–æ–¥ –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
        try:
            title = re.sub(r"\s+\(\d{4}\)\s*$", "", title).strip()
        except Exception:
            pass

        # –µ—Å–ª–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ –µ—Å—Ç—å ¬´RU / EN¬ª ‚Äî –±–µ—Ä—ë–º –ª–µ–≤—É—é —á–∞—Å—Ç—å (RU)
        try:
            if "/" in title:
                left = title.split("/", 1)[0].strip()
                if left:
                    title = left
        except Exception:
            pass

        # –µ—Å–ª–∏ –µ—Å—Ç—å RU + EN –±–µ–∑ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ü–∞—Ü–∞–Ω—ã The Boys") ‚Äî
        # —É–±–∏—Ä–∞–µ–º –∞–Ω–≥–ª. —Ö–≤–æ—Å—Ç, –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å >=2 –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö —Å–ª–æ–≤–∞ (—á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–∏–ø–∞ "–ú–∏—Å—Ç–µ—Ä Robot").
        try:
            has_cyr = bool(re.search(r"[–ê-–Ø–∞-—è–Å—ë]", title))
            latin_words = re.findall(r"[A-Za-z]{2,}", title)
            if has_cyr:
                # "–ü–∞—Ü–∞–Ω—ã (The Boys)" -> "–ü–∞—Ü–∞–Ω—ã"
                m = re.match(r"^(.+?)\s*\([^)]*[A-Za-z][^)]*\)\s*$", title)
                if m:
                    left = (m.group(1) or "").strip()
                    if left:
                        title = left

                # "–ü–∞—Ü–∞–Ω—ã ‚Äî The Boys" -> "–ü–∞—Ü–∞–Ω—ã"
                m = re.match(r"^(.+?)\s*[‚Äî-]\s*[A-Za-z].*$", title)
                if m:
                    left = (m.group(1) or "").strip()
                    if left:
                        title = left

            if has_cyr and len(latin_words) >= 2:
                m = re.match(r"^(.+?)\s+[A-Za-z].*$", title)
                if m:
                    title = (m.group(1) or "").strip()
        except Exception:
            pass

        return _normalize_display_name(title) if title else "series"

    def _parse_seasons_from_html(html: str) -> list[int]:
        soup = BeautifulSoup(html, "html.parser")
        nums: list[int] = []
        # —Ç–∏–ø–æ–≤–æ–π –±–ª–æ–∫: "–°–µ–∑–æ–Ω—ã:" + span.p-r-sm.p-t-sm
        for el in soup.select("span.p-r-sm.p-t-sm, a.p-r-sm.p-t-sm, button.p-r-sm.p-t-sm"):
            try:
                t = el.get_text(" ", strip=True)
            except Exception:
                t = ""
            t = (t or "").strip()
            if not t.isdigit():
                continue
            try:
                n = int(t)
            except Exception:
                continue
            if 1 <= n <= 99:
                nums.append(n)
        nums = sorted({n for n in nums})
        return nums

    def _find_season_elements() -> dict[int, object]:
        # Selenium —ç–ª–µ–º–µ–Ω—Ç—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –º–æ–∂–Ω–æ –∫–ª–∏–∫–∞—Ç—å
        try:
            from selenium.webdriver.common.by import By
        except Exception:
            return {}
        mapping: dict[int, object] = {}
        try:
            elems = driver.find_elements(By.CSS_SELECTOR, "span.p-r-sm.p-t-sm, a.p-r-sm.p-t-sm, button.p-r-sm.p-t-sm")
        except Exception:
            elems = []
        for el in elems or []:
            try:
                t = str(el.text or "").strip()
            except Exception:
                t = ""
            if not t.isdigit():
                continue
            try:
                n = int(t)
            except Exception:
                continue
            if 1 <= n <= 99 and n not in mapping:
                mapping[n] = el
        return mapping

    def _extract_episodes_from_html(html: str) -> list[tuple[int | None, str | None]]:
        soup = BeautifulSoup(html, "html.parser")
        out: list[tuple[int | None, str | None]] = []

        # –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —ç–ø–∏–∑–æ–¥–æ–≤ (–ø–æ —Å–∫—Ä–∏–Ω—É: div.row.m-b)
        cards = soup.select("div.row.m-b .owl-item")
        if not cards:
            # fallback: –ø—Ä–æ—Å—Ç–æ –≤—Å–µ owl-item –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            cards = soup.select(".owl-item")

        for card in cards:
            href = None
            try:
                a = card.select_one("a[href]")
                if a:
                    href = a.get("href")
            except Exception:
                href = None
            if not href:
                try:
                    href = card.get("data-href") or card.get("data-url")
                except Exception:
                    href = None

            if href:
                href = _ensure_abs(str(href))

            ep_num = None
            try:
                text = card.get_text(" ", strip=True)
            except Exception:
                text = ""
            text = (text or "").strip()
            if text:
                m = re.search(r"(?:–≠–ø–∏–∑–æ–¥|Episode)\s*(\d{1,3})\b", text, re.I)
                if m:
                    try:
                        ep_num = int(m.group(1))
                    except Exception:
                        ep_num = None

            # —Ñ–∏–ª—å—Ç—Ä—É–µ–º —è–≤–Ω–æ ¬´–Ω–µ —ç–ø–∏–∑–æ–¥—ã¬ª: –µ—Å–ª–∏ –Ω–µ—Ç –Ω–æ–º–µ—Ä–∞ –∏ –Ω–µ—Ç —Å—Å—ã–ª–∫–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if ep_num is None and not href:
                continue

            out.append((ep_num, href))

        # fallback: —Å—Å—ã–ª–∫–∏ –≤ –±–ª–æ–∫–µ —ç–ø–∏–∑–æ–¥–æ–≤
        if not out:
            for a in soup.select("div.row.m-b a[href*='/item/'], div.row.m-b a[href]"):
                try:
                    href = a.get("href")
                except Exception:
                    href = None
                if not href:
                    continue
                href = _ensure_abs(str(href))
                text = ""
                try:
                    text = (a.get_text(" ", strip=True) or "").strip()
                except Exception:
                    text = ""
                ep_num = None
                m = re.search(r"(?:–≠–ø–∏–∑–æ–¥|Episode)\s*(\d{1,3})\b", text, re.I)
                if m:
                    try:
                        ep_num = int(m.group(1))
                    except Exception:
                        ep_num = None
                out.append((ep_num, href))

        return out

    def _collect_episodes_interactive(base_url: str) -> list[dict]:
        """
        –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–±—Ä–∞—Ç—å –≤—Å–µ —ç–ø–∏–∑–æ–¥—ã —Ç–µ–∫—É—â–µ–≥–æ —Å–µ–∑–æ–Ω–∞:
        - 1 —Ä–∞–∑ –ø–∞—Ä—Å–∏–º HTML —Ü–µ–ª–∏–∫–æ–º
        - –µ—Å–ª–∏ –µ—Å—Ç—å dots (owl-dot) ‚Äî –∫–ª–∏–∫–∞–µ–º –∫–∞–∂–¥—ã–π –∏ –¥–æ–±–∏—Ä–∞–µ–º
        - –µ—Å–ª–∏ –µ—Å—Ç—å next-—Å—Ç—Ä–µ–ª–∫–∞ ‚Äî –∫–ª–∏–∫–∞–µ–º –ø–æ–∫–∞ –ø–æ—è–≤–ª—è—é—Ç—Å—è –Ω–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏
        """
        try:
            from selenium.webdriver.common.by import By
        except Exception:
            By = None

        seen: dict[str, int | None] = {}  # url -> ep_num

        def _merge(entries: list[tuple[int | None, str | None]]):
            for ep_num, href in entries:
                if not href:
                    continue
                if href not in seen:
                    seen[href] = ep_num
                else:
                    # –µ—Å–ª–∏ —Ä–∞–Ω—å—à–µ –Ω–æ–º–µ—Ä –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏, –∞ —Å–µ–π—á–∞—Å —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏ ‚Äî –æ–±–Ω–æ–≤–∏–º
                    if seen[href] is None and ep_num is not None:
                        seen[href] = ep_num

        # —Ç–µ–∫—É—â–∏–π HTML
        try:
            _merge(_extract_episodes_from_html(driver.page_source))
        except Exception:
            pass

        if not By:
            # –±–µ–∑ Selenium —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –±–æ–ª—å—à–µ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–¥–µ–ª–∞–µ–º
            pass
        else:
            # dots
            try:
                dots = driver.find_elements(By.CSS_SELECTOR, "div.row.m-b .owl-dots button, div.row.m-b .owl-dots .owl-dot")
            except Exception:
                dots = []
            if dots and len(dots) > 1:
                for i, dot in enumerate(dots):
                    if _cancelled():
                        break
                    try:
                        driver.execute_script("arguments[0].click();", dot)
                        time.sleep(0.35)
                        _merge(_extract_episodes_from_html(driver.page_source))
                    except Exception:
                        continue

            # next-—Å—Ç—Ä–µ–ª–∫–∞
            try:
                next_btns = driver.find_elements(By.CSS_SELECTOR, "div.row.m-b .owl-nav .owl-next, div.row.m-b .owl-next")
            except Exception:
                next_btns = []
            next_btn = next_btns[0] if next_btns else None
            if next_btn is not None:
                stagnation = 0
                for _ in range(40):
                    if _cancelled():
                        break
                    before = len(seen)
                    try:
                        driver.execute_script("arguments[0].click();", next_btn)
                    except Exception:
                        break
                    time.sleep(0.35)
                    try:
                        _merge(_extract_episodes_from_html(driver.page_source))
                    except Exception:
                        pass
                    if len(seen) <= before:
                        stagnation += 1
                        if stagnation >= 3:
                            break
                    else:
                        stagnation = 0

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º: –µ—Å–ª–∏ –¥–ª—è —á–∞—Å—Ç–∏ —Å—Å—ã–ª–æ–∫ –Ω–µ –Ω–∞—à–ª–∏ –Ω–æ–º–µ—Ä ‚Äî —Ä–∞–∑–¥–∞–¥–∏–º –ø–æ –ø–æ—Ä—è–¥–∫—É
        ordered_urls = list(seen.keys())
        # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Ç–µ, —É –∫–æ–≥–æ –Ω–æ–º–µ—Ä –∏–∑–≤–µ—Å—Ç–µ–Ω
        numbered = [(u, n) for u, n in seen.items() if n is not None]
        if numbered:
            # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É, –∑–∞—Ç–µ–º –æ—Å—Ç–∞—Ç–æ–∫
            numbered.sort(key=lambda x: int(x[1] or 0))
            ordered_urls = [u for u, _ in numbered] + [u for u in ordered_urls if seen.get(u) is None]

        items: list[dict] = []
        next_auto = 1
        for u in ordered_urls:
            ep = seen.get(u)
            if ep is None:
                ep = next_auto
                next_auto += 1
            items.append({"episode": int(ep), "url": u})
        return items

    series_url = _ensure_abs(series_url)
    if not series_url:
        raise RuntimeError("–ü—É—Å—Ç–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å–µ—Ä–∏–∞–ª.")

    if _cancelled():
        return {"title": "series", "seasons": {}}

    _log(status_cb, f"üì∫ –ê–Ω–∞–ª–∏–∑ —Å–µ—Ä–∏–∞–ª–∞: {series_url}")
    driver.get(series_url)

    if not _ensure_cf_solved():
        raise RuntimeError("Cloudflare –Ω–µ –ø—Ä–æ–π–¥–µ–Ω (—Ç–∞–π–º–∞—É—Ç).")

    try:
        WebDriverWait(driver, 30).until(lambda d: d.execute_script("return document.readyState") == "complete")
    except Exception:
        pass

    try:
        if "/user/login" in (driver.current_url or "").lower():
            raise RuntimeError("–¢—Ä–µ–±—É–µ—Ç—Å—è –≤—Ö–æ–¥ –≤ Kino.pub")
    except Exception:
        pass

    html0 = driver.page_source
    title = _extract_title(html0)
    seasons = _parse_seasons_from_html(html0)
    season_elems = _find_season_elements()
    if not seasons:
        seasons = sorted(season_elems.keys()) if season_elems else [1]

    result: dict = {"title": title, "seasons": {}}

    # –µ—Å–ª–∏ —Å–µ–∑–æ–Ω—ã –Ω–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è/–Ω–µ –∫–ª–∏–∫–∞—é—Ç—Å—è ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–æ–±–µ—Ä—ë–º ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª –≤ —Å–µ–∑–æ–Ω 1
    if not season_elems or len(seasons) <= 1:
        s_num = int(seasons[0] if seasons else 1)
        eps = _collect_episodes_interactive(series_url)
        # –í–∞–∂–Ω–æ: –¥–∞–∂–µ –µ—Å–ª–∏ —Å–∞–π—Ç –Ω–µ –º–µ–Ω—è–µ—Ç URL –ø—Ä–∏ –≤—ã–±–æ—Ä–µ —ç–ø–∏–∑–æ–¥–∞, –¥–µ–ª–∞–µ–º
        # —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏ —á–µ—Ä–µ–∑ query params season/episode, —á—Ç–æ–±—ã:
        # - –Ω–µ –±—ã–ª–æ –¥—É–±–ª–µ–π –º–µ–∂–¥—É —Å–µ–∑–æ–Ω–∞–º–∏
        # - –º–æ–∂–Ω–æ –±—ã–ª–æ —Å–∫–∞—á–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π SxxExx
        try:
            for e in eps or []:
                try:
                    ep = int((e or {}).get("episode") or 1)
                except Exception:
                    ep = 1
                base = (e or {}).get("url") or series_url
                e["url"] = _series_episode_url(str(base), s_num, ep)
        except Exception:
            pass

        result["seasons"][s_num] = eps
        # –µ—Å–ª–∏ —Å—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞—à–ª–∏—Å—å ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ —à–∞–±–ª–æ–Ω—É
        if not result["seasons"].get(s_num):
            # fallback: —Ö–æ—Ç—è –±—ã 1 —ç–ø–∏–∑–æ–¥ –ø–æ –±–∞–∑–æ–≤–æ–π —Å—Å—ã–ª–∫–µ
            result["seasons"][s_num] = [{"episode": 1, "url": _series_episode_url(series_url, s_num, 1)}]
        return result

    # –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –ø–æ —Å–µ–∑–æ–Ω–∞–º
    for s_num in seasons:
        if _cancelled():
            break
        _log(status_cb, f"üì∫ –°–µ–∑–æ–Ω {s_num}‚Ä¶")
        el = season_elems.get(int(s_num))
        if el is not None:
            try:
                driver.execute_script("arguments[0].click();", el)
            except Exception:
                try:
                    el.click()
                except Exception:
                    pass
            time.sleep(0.6)

        eps = _collect_episodes_interactive(series_url)
        # –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏—Å—å —è–≤–Ω—ã–µ —Å—Å—ã–ª–∫–∏ ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ —à–∞–±–ª–æ–Ω—É season/episode
        if not eps:
            eps = [{"episode": 1, "url": _series_episode_url(series_url, int(s_num), 1)}]
        else:
            # –í–∞–∂–Ω–æ: –¥–∞–∂–µ –µ—Å–ª–∏ —Å–∞–π—Ç –Ω–µ –º–µ–Ω—è–µ—Ç URL –ø—Ä–∏ –≤—ã–±–æ—Ä–µ —ç–ø–∏–∑–æ–¥–∞, –¥–µ–ª–∞–µ–º
            # —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏ —á–µ—Ä–µ–∑ query params season/episode, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –¥—É–±–ª–µ–π –º–µ–∂–¥—É —Å–µ–∑–æ–Ω–∞–º–∏.
            for e in eps:
                try:
                    ep = int((e or {}).get("episode") or 1)
                except Exception:
                    ep = 1
                try:
                    base = (e or {}).get("url") or series_url
                    e["url"] = _series_episode_url(str(base), int(s_num), ep)
                except Exception:
                    pass

        result["seasons"][int(s_num)] = eps

    return result


def _kino_cookie_mtime() -> int | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç mtime —Ñ–∞–π–ª–∞ cookies (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö) –∏–ª–∏ None.
    –ù—É–∂–µ–Ω, —á—Ç–æ–±—ã –ø–æ—Å–ª–µ –ª–æ–≥–∏–Ω–∞ –æ–±–Ω–æ–≤–ª—è—Ç—å cookies –≤–æ –≤—Å–µ—Ö –¥—Ä–∞–π–≤–µ—Ä–∞—Ö –ø—É–ª–∞.
    """
    try:
        from kino_parser import COOKIE_FILE, COOKIE_FILE_LEGACY

        path = COOKIE_FILE if os.path.exists(COOKIE_FILE) else COOKIE_FILE_LEGACY
        if os.path.exists(path):
            return int(os.path.getmtime(path) or 0)
    except Exception:
        return None
    return None


# -------------------------------------------------------
# –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –Ω–∞ —Å–∞–π—Ç–µ
# -------------------------------------------------------
def search_titles(query: str, limit=1, status_cb=None, driver=None, cancel_event=None) -> List[Tuple[str, str]]:
    # –∫–æ–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –æ—Ç–º–µ–Ω–∞ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤—ã–∑—ã–≤–∞—é—â–∏–º –∫–æ–¥–æ–º)
    if getattr(cancel_event, "is_set", lambda: False)():
        return []
    if driver is None:
        raise RuntimeError("search_titles –æ–∂–∏–¥–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π driver")

    from urllib.parse import quote_plus
    url = f"{KINOPUB_BASE}/item/search?query=" + quote_plus(query)
    _log(status_cb, f"üîç –ü–æ–∏—Å–∫: {url}")
    driver.get(url)

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".item-title a"))
        )
    except Exception:
        _log(status_cb, "‚ö†Ô∏è –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å.")
        return []

    html = driver.page_source
    soup = BeautifulSoup(html, "html.parser")
    results = []

    for a in soup.select(".item-title a[href*='/item/']")[:limit]:
        title = a.get_text(strip=True)
        href = a["href"]
        if not href.startswith("http"):
            href = KINOPUB_BASE + href
        results.append((title, href))

    _log(status_cb, f"üîé –ù–∞–π–¥–µ–Ω–æ: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç(–æ–≤).")
    return results


# -------------------------------------------------------
# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ‚Äú–∫—Ä–∞—Å–∏–≤–æ–≥–æ‚Äù –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
# -------------------------------------------------------
def _extract_display_name(driver, item_url, cancel_event=None) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç '–†—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (YYYY)' —Å —á–∏—Å—Ç–∫–æ–π —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤."""
    try:
        if getattr(cancel_event, "is_set", lambda: False)():
            return "video"
        driver.get(item_url)
        WebDriverWait(driver, 25).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "meta[property='og:title'], h1, .item-title"))
        )
        if getattr(cancel_event, "is_set", lambda: False)():
            return "video"
        html = driver.page_source
        soup = BeautifulSoup(html, "html.parser")

        title_h1 = soup.select_one("h1, .item-title")
        title_ru = title_h1.get_text(strip=True) if title_h1 else (driver.title or "").strip()

        title_ru = re.split(r"[_/]", title_ru)[0].strip()
        title_ru = re.sub(r'\s+\(\d{4}\)$', '', title_ru)

        year = None
        for tr in soup.select("table.table.table-striped tr"):
            tds = tr.find_all(["td", "th"])
            if len(tds) >= 2:
                label = tds[0].get_text(" ", strip=True).lower()
                if any(k in label for k in ("–≥–æ–¥ –≤—ã—Ö–æ–¥–∞", "–≥–æ–¥ –≤—ã–ø—É—Å–∫–∞", "–≥–æ–¥")):
                    text = tds[1].get_text(" ", strip=True)
                    m = re.search(r"\b(19|20)\d{2}\b", text)
                    if m:
                        year = m.group(0)
                        break

        if not year:
            m = re.search(r"\b(19|20)\d{2}\b", html)
            year = m.group(0) if m else ""

        name = f"{title_ru} ({year})" if year else title_ru

        # –ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Windows ‚Üí –ø—Ä–æ–±–µ–ª
        name = re.sub(r'[\\/:*?"<>|]', " ", name)

        # –°—Ö–ª–æ–ø—ã–≤–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –ø—Ä–æ–±–µ–ª—ã
        name = re.sub(r"\s{2,}", " ", name)

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–æ—á–∫–∏ –ø–æ –∫—Ä–∞—è–º (Windows –Ω–µ –ª—é–±–∏—Ç —Ç–∞–∫–∏–µ –∏–º–µ–Ω–∞)
        name = name.strip(" .")

        return name or "video"


    except Exception:
        slug = re.sub(r"[#?].*$", "", item_url).rstrip("/").split("/")[-1]
        return (slug.replace("-", " ").strip() or "video")

def _normalize_display_name(name: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è) –¥–ª—è Windows:
    - —É–±–∏—Ä–∞–µ—Ç .mp4 (–µ—Å–ª–∏ –ø—Ä–∏–ª–µ—Ç–µ–ª–æ)
    - –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã -> –ø—Ä–æ–±–µ–ª
    - —Å—Ö–ª–æ–ø—ã–≤–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã
    - —Ç—Ä–∏–º–º–∏—Ç –ø—Ä–æ–±–µ–ª—ã/—Ç–æ—á–∫–∏ –ø–æ –∫—Ä–∞—è–º
    """
    name = (name or "").strip()
    if not name:
        return "video"

    try:
        if name.lower().endswith(".mp4"):
            name = name[:-4]
    except Exception:
        pass

    try:
        name = re.sub(r'[\\/:*?"<>|]', " ", name)
        name = re.sub(r"\s{2,}", " ", name)
        name = name.strip(" .")
    except Exception:
        pass

    return name or "video"


# -------------------------------------------------------
# –û–î–ù–û —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ (—Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–¥–∞—Ç—å –≤–Ω–µ—à–Ω–∏–π driver –∏–∑ –ø—É–ª–∞)
# -------------------------------------------------------
def download(
    query_or_url: str,
    out_dir=".",
    status_cb=None,
    driver=None,
    cancel_event=None,
    audio_select_cb=None,
    defer_mux: bool = False,
    display_name_override: str | None = None,
    audio_parallel_tracks: int | None = None,
) -> bool:
    """
    –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ñ–∏–ª—å–º–∞.
    –ï—Å–ª–∏ driver –ø–µ—Ä–µ–¥–∞–Ω (–∏–∑ DriverPool) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –∏–Ω–∞—á–µ —Å–∞–º–∏ –ø–æ–¥–Ω–∏–º–µ–º —Å–∫—Ä—ã—Ç—ã–π UC.
    """
    os.makedirs(out_dir, exist_ok=True)

    internal_driver = None
    try:
        # ======= –ï–°–õ–ò –ü–ï–†–ï–î–ê–ù driver (–ø—É–ª UC) =======
        if driver is not None:
            try:
                cookie_mtime = _kino_cookie_mtime()
                loaded_mtime = int(getattr(driver, "_kino_cookies_mtime", 0) or 0)
                need_reload = (not getattr(driver, "_kino_cookies_loaded", False)) or (
                    cookie_mtime and cookie_mtime != loaded_mtime
                )

                if need_reload:
                    driver.get(KINOPUB_BASE + "/")
                    ok = bool(load_cookies(driver))
                    driver.refresh()
                    setattr(driver, "_kino_cookies_loaded", ok)
                    if cookie_mtime:
                        setattr(driver, "_kino_cookies_mtime", int(cookie_mtime))
                    # –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ª–∏–≤–∫–∏ cookies –ª—É—á—à–µ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏–Ω
                    setattr(driver, "_kino_login_ok", False)
                    setattr(driver, "_kino_login_checked_at", 0)
            except Exception as e:
                _log(status_cb, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–≥—Ä—É–∑–∫–∏ cookies –≤ –¥—Ä–∞–π–≤–µ—Ä –ø—É–ª–∞: {e}")

            # –ë—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å: –µ—Å–ª–∏ —ç—Ç–∏–º –¥—Ä–∞–π–≤–µ—Ä–æ–º —É–∂–µ –Ω–µ–¥–∞–≤–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–ª–∏ –ª–æ–≥–∏–Ω ‚Äî
            # –Ω–µ –¥–µ–ª–∞–µ–º –ª–∏—à–Ω–∏—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (–æ–Ω–∏ –∑–∞–º–µ—Ç–Ω–æ –∑–∞–º–µ–¥–ª—è—é—Ç —Å—Ç–∞—Ä—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è).
            try:
                checked_at = float(getattr(driver, "_kino_login_checked_at", 0) or 0)
                login_ok = bool(getattr(driver, "_kino_login_ok", False))
                if (not login_ok) or (time.time() - checked_at > 180):
                    if not _check_login_on(driver, status_cb):
                        # –ò–Ω–æ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–∂–Ω–æ –ø–∞–¥–∞–µ—Ç –∏–∑-–∑–∞ CF/—Ç–∞–π–º–∞—É—Ç–∞.
                        # –ï—Å–ª–∏ cookies –≤—ã–≥–ª—è–¥—è—Ç –≤–∞–ª–∏–¥–Ω–æ ‚Äî –ø—Ä–æ–±—É–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å (—Ä–µ–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å—ë —Ä–∞–≤–Ω–æ –±—É–¥–µ—Ç –Ω–∞ item_url).
                        try:
                            from kino_parser import has_valid_session

                            if has_valid_session():
                                _log(
                                    status_cb,
                                    "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å —Å–µ—Å—Å–∏—é –≤ –±—Ä–∞—É–∑–µ—Ä–µ (–≤–æ–∑–º–æ–∂–Ω–æ CF/—Ç–∞–π–º–∞—É—Ç) ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞—é –ø–æ cookies‚Ä¶",
                                )
                                setattr(driver, "_kino_login_ok", True)
                                setattr(driver, "_kino_login_checked_at", time.time())
                            else:
                                setattr(driver, "_kino_login_ok", False)
                                setattr(driver, "_kino_login_checked_at", time.time())
                                _log(status_cb, "‚ö†Ô∏è –°–µ—Å—Å–∏—è –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞ ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—Ö–æ–¥.")
                                return False
                        except Exception:
                            setattr(driver, "_kino_login_ok", False)
                            setattr(driver, "_kino_login_checked_at", time.time())
                            _log(status_cb, "‚ö†Ô∏è –°–µ—Å—Å–∏—è –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞ ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—Ö–æ–¥.")
                            return False
                    else:
                        setattr(driver, "_kino_login_ok", True)
                        setattr(driver, "_kino_login_checked_at", time.time())
            except Exception:
                if not _check_login_on(driver, status_cb):
                    try:
                        from kino_parser import has_valid_session

                        if not has_valid_session():
                            _log(status_cb, "‚ö†Ô∏è –°–µ—Å—Å–∏—è –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞ ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—Ö–æ–¥.")
                            return False
                        _log(
                            status_cb,
                            "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å —Å–µ—Å—Å–∏—é –≤ –±—Ä–∞—É–∑–µ—Ä–µ (–≤–æ–∑–º–æ–∂–Ω–æ CF/—Ç–∞–π–º–∞—É—Ç) ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞—é –ø–æ cookies‚Ä¶",
                        )
                    except Exception:
                        _log(status_cb, "‚ö†Ô∏è –°–µ—Å—Å–∏—è –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞ ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—Ö–æ–¥.")
                        return False
                try:
                    setattr(driver, "_kino_login_ok", True)
                    setattr(driver, "_kino_login_checked_at", time.time())
                except Exception:
                    pass

            use_driver = driver

        else:
            raise RuntimeError("Download() must be called with driver ‚Äî internal UC driver forbidden.")

        # ======= –î–ê–õ–¨–®–ï –ò–°–ü–û–õ–¨–ó–£–ï–ú use_driver =======

        if getattr(cancel_event, "is_set", lambda: False)():
            return False

        # URL –∏–ª–∏ –ø–æ–∏—Å–∫
        if not query_or_url.startswith("http"):
            results = search_titles(
                query_or_url,
                limit=1,
                status_cb=status_cb,
                driver=use_driver,
                cancel_event=cancel_event,
            )
            if not results:
                _log(status_cb, "‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
                return False
            _, item_url = results[0]
        else:
            item_url = query_or_url

        if getattr(cancel_event, "is_set", lambda: False)():
            return False

        _log(status_cb, "üìã –ò–∑–≤–ª–µ–∫–∞—é –Ω–∞–∑–≤–∞–Ω–∏–µ...")
        if display_name_override:
            display_name = str(display_name_override)
        else:
            display_name = _extract_display_name(use_driver, item_url, cancel_event=cancel_event)
        display_name = _normalize_display_name(display_name)

        # —Ñ–æ—Ä–º–∏—Ä—É–µ–º output
        out_path = os.path.join(out_dir, display_name + ".mp4")

        _log(status_cb, f"üé¨ –§–∞–π–ª: {os.path.basename(out_path)}")

        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –Ω–µ –∫–∞—á–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ (—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ—á–µ—Ä–µ–¥–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞).
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—Å–µ–≥–¥–∞ –º–æ–∂–µ—Ç —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª –≤—Ä—É—á–Ω—É—é –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–Ω–æ–≤–∞.
        try:
            if os.path.isfile(out_path) and os.path.getsize(out_path) > 0:
                _log(status_cb, "‚úÖ –£–∂–µ —Å–∫–∞—á–∞–Ω–æ (—Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)")
                return True
        except Exception:
            pass

        # --- –∑–¥–µ—Å—å —Ç–æ–ª—å–∫–æ –∑–∞–ø—É—Å–∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ ---
        _log(status_cb, "üé¨ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞‚Ä¶ (–∞–Ω–∞–ª–∏–∑ HLS)")

        ok = download_by_item_url(
            item_url,
            out_path,
            driver=use_driver,
            status_cb=status_cb,
            cancel_event=cancel_event,
            audio_select_cb=audio_select_cb,
            defer_mux=defer_mux,
            audio_parallel_tracks=audio_parallel_tracks,
        )

        if getattr(cancel_event, "is_set", lambda: False)():
            return False

        # –¢–µ–ø–µ—Ä—å download_by_item_url() —Ä–∞–±–æ—Ç–∞–µ—Ç –°–ò–ù–•–†–û–ù–ù–û:
        # –∏ –∞–Ω–∞–ª–∏–∑ HLS, –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ, –∏ MUX –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –Ω–µ–≥–æ.
        # –ó–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –æ–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

        if not ok:
            _log(status_cb, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏.")
        else:
            if defer_mux:
                _log(status_cb, "üéû –ì–æ—Ç–æ–≤–æ –∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏.")
            else:
                _log(status_cb, "‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        return ok

    except Exception as e:
        _log(status_cb, f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False

    finally:
        if internal_driver:
            try:
                internal_driver.quit()
            except Exception:
                pass


# -------------------------------------------------------
# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–º URL (–±—ã—Å—Ç—Ä—ã–π –±–∞—Ç—á)
# -------------------------------------------------------
def download_multiple(urls, out_dir, status_cb=None):
    """
    –ü—Ä–æ—Å—Ç–æ–π –±–∞—Ç—á: –±–µ—Ä—ë–º –¥—Ä–∞–π–≤–µ—Ä –∏–∑ –ø—É–ª–∞ ‚Üí –¥–æ—Å—Ç–∞—ë–º m3u8 ‚Üí —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∫–∞—á–∞–µ–º –∏ –º—É–∫—Å—É–µ–º.
    """
    os.makedirs(out_dir, exist_ok=True)
    pool = DriverPool(max_drivers=2, status_cb=status_cb)
    try:
        for url in urls:
            drv = pool.acquire(timeout=10)
            try:
                video_m3u8, hdrs, audios = get_hls_info(url, driver=drv)
                if not video_m3u8:
                    _log(status_cb, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: –Ω–µ—Ç –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è {url}")
                    continue

                # –ö—Ä–∞—Å–∏–≤–æ–µ –∏–º—è (–Ω–µ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ ‚Äî –±—ã—Å—Ç—Ä–æ)
                safe_name = _extract_display_name(drv, url)
                out_path = os.path.join(out_dir, safe_name + ".mp4")

                # start_hls_download —Ç–µ–ø–µ—Ä—å –±–ª–æ–∫–∏—Ä—É—é—â–∏–π
                start_hls_download(video_m3u8, audios, hdrs, out_path, status_cb)

            finally:
                pool.release(drv)

    finally:
        pool.close_all()



# =======================================================
#                –û–ß–ï–†–ï–î–¨ –ó–ê–ì–†–£–ó–û–ö (–æ–Ω–ª–∞–π–Ω –¥–æ–∫–∏–¥–∫–∞)
# =======================================================
class QueueDownloader:
    """
    –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –æ—á–µ—Ä–µ–¥—å –∑–∞–≥—Ä—É–∑–æ–∫:
      - add(url_or_query): –¥–æ–∫–∏–¥—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á—É –Ω–∞ –ª–µ—Ç—É
      - concurrency: —Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫
      - –≤–Ω—É—Ç—Ä–∏ ‚Äî DriverPool, –∫–∞–∂–¥—ã–π –≤–æ—Ä–∫–µ—Ä –±–µ—Ä—ë—Ç –¥—Ä–∞–π–≤–µ—Ä, –ø–æ–ª—É—á–∞–µ—Ç m3u8 –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç ffmpeg
      - –¥—Ä–∞–π–≤–µ—Ä –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ ffmpeg (—á—Ç–æ–±—ã –Ω–µ –¥–µ—Ä–∂–∞—Ç—å CDP-—Å–µ—Å—Å–∏—é)
    """

    def __init__(self, out_dir: str, concurrency: int = 2, status_cb: Optional[Callable[[str], None]] = None):
        self.out_dir = out_dir
        self.status_cb = status_cb
        os.makedirs(self.out_dir, exist_ok=True)

        self.q: "queue.Queue[str]" = queue.Queue()
        self.stop_event = threading.Event()
        self.pool = DriverPool(max_drivers=max(1, concurrency), status_cb=status_cb)

        # –ø–æ–¥–Ω–∏–º–∞–µ–º –≤–æ—Ä–∫–µ—Ä—ã
        self.workers: list[threading.Thread] = []

        for i in range(max(1, concurrency)):
            t = threading.Thread(target=self._worker, name=f"dl-worker-{i+1}", daemon=True)
            t.start()
            self.workers.append(t)

        _log(self.status_cb, f"üßµ –û—á–µ—Ä–µ–¥—å –≥–æ—Ç–æ–≤–∞: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫ = {concurrency}")

    def add(self, query_or_url: str):
        """–î–æ–±–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É (URL –∏–ª–∏ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å)."""
        self.q.put(query_or_url)
        _log(self.status_cb, f"‚ûï –í –æ—á–µ—Ä–µ–¥—å: {query_or_url}")

    def _worker(self):
        while not self.stop_event.is_set():
            try:
                task = self.q.get(timeout=0.2)
            except queue.Empty:
                continue

            drv = None
            try:
                drv = self.pool.acquire(timeout=15, profile_tag="run")

                # –±—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥—Ä–µ–≤ cookies (–æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –¥—Ä–∞–π–≤–µ—Ä)
                try:
                    if not getattr(drv, "_kino_cookies_loaded", False):
                        drv.get("chrome://newtab")
                        load_cookies(drv)
                        drv.get(KINOPUB_BASE + "/")
                        setattr(drv, "_kino_cookies_loaded", True)

                except Exception as e:
                    _log(self.status_cb, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–≥—Ä—É–∑–∫–∏ cookies: {e}")

                # –µ—Å–ª–∏ –¥–∞–ª–∏ –Ω–µ URL ‚Äî —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º
                if not task.startswith("http"):
                    results = search_titles(task, limit=1, status_cb=self.status_cb, driver=drv)
                    if not results:
                        _log(self.status_cb, f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {task}")
                        self.q.task_done()
                        self.pool.release(drv)
                        continue
                    _, item_url = results[0]
                else:
                    item_url = task

                # –∫—Ä–∞—Å–∏–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ (—Ä—É—Å—Å–∫–æ–µ + –≥–æ–¥)
                try:
                    display_name = _extract_display_name(drv, item_url)
                except Exception:
                    # –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ ‚Äî fallback
                    display_name = os.path.basename(item_url).split("?")[0]

                # --- –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –∏–º–µ–Ω–∏ ---
                # –∏–Ω–æ–≥–¥–∞ _extract_display_name() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–∂–µ '–ù–∞–∑–≤–∞–Ω–∏–µ (2025).mp4'
                # –∏–∑-–∑–∞ —ç—Ç–æ–≥–æ –ø–æ—è–≤–ª—è–µ—Ç—Å—è '.mp4.mp4.part' ‚Üí ffmpeg –ø–∞–¥–∞–µ—Ç
                if display_name.lower().endswith(".mp4"):
                    display_name = display_name[:-4]

                out_path = os.path.join(self.out_dir, display_name + ".mp4")
                _log(self.status_cb, f"üé¨ [{threading.current_thread().name}] ‚Üí {os.path.basename(out_path)}")


                # –ø–æ–ª—É—á–∞–µ–º m3u8/–∑–∞–≥–æ–ª–æ–≤–∫–∏/–∞—É–¥–∏–æ
                video_m3u8, hdrs, audios = get_hls_info(item_url, driver=drv)
                if not video_m3u8:
                    _log(self.status_cb, f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ (–Ω–µ—Ç HLS): {item_url}")
                    self.q.task_done()
                    self.pool.release(drv)
                    continue

                # —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∫–∞—á–∞–µ–º –∏ –º—É–∫—Å—É–µ–º; –¥—Ä–∞–π–≤–µ—Ä –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω
                start_hls_download(video_m3u8, audios, hdrs, out_path, self.status_cb)
                _log(self.status_cb, f"‚úÖ –°–∫–∞—á–∞–Ω–æ: {out_path}")


            except Exception as e:
                _log(self.status_cb, f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞: {e}")

            finally:
                try:
                    if drv:
                        self.pool.release(drv)
                finally:
                    self.q.task_done()
    def wait_all(self):
        """–î–æ–∂–¥–∞—Ç—å—Å—è, –∫–æ–≥–¥–∞ –æ—á–µ—Ä–µ–¥—å –æ–ø—É—Å—Ç–µ–µ—Ç (–≤—Å–µ –≤–æ—Ä–∫–µ—Ä—ã –¥–æ–∫–∞—á–∞—é—Ç —Å–≤–æ—ë)."""
        self.q.join()

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–æ—Ä–∫–µ—Ä–æ–≤ –∏ –∑–∞–∫—Ä—ã—Ç—å –¥—Ä–∞–π–≤–µ—Ä—ã –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –∑–∞–¥–∞—á."""
        self.stop_event.set()
        # –¥–æ–∂–¥–∞—Ç—å—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –∑–∞–¥–∞—á
        self.wait_all()

        # —Ä–∞–∑–±—É–¥–∏—Ç—å –∏ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –≤–æ—Ä–∫–µ—Ä–æ–≤
        for _ in self.workers:
            self.q.put_nowait("")
        for t in self.workers:
            t.join(timeout=1.0)

        # –∑–∞–∫—Ä—ã—Ç—å –¥—Ä–∞–π–≤–µ—Ä—ã –ø—É–ª–∞
        self.pool.close_all()
        _log(self.status_cb, "üßπ –û—á–µ—Ä–µ–¥—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –¥—Ä–∞–π–≤–µ—Ä—ã –∑–∞–∫—Ä—ã—Ç—ã.")

        # –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–æ—Ä–∫–µ—Ä–æ–≤
        for _ in self.workers:
            self.q.put_nowait("")  # —Ä–∞–∑–±—É–¥–∏—Ç—å
        for t in self.workers:
            t.join(timeout=1.0)

        # –∑–∞–∫—Ä—ã—Ç—å –≤—Å–µ –¥—Ä–∞–π–≤–µ—Ä—ã –ø—É–ª–∞
        self.pool.close_all()
        _log(self.status_cb, "üßπ –û—á–µ—Ä–µ–¥—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –¥—Ä–∞–π–≤–µ—Ä—ã –∑–∞–∫—Ä—ã—Ç—ã.")


# -------------------------------------------------------
# –°–∏–Ω–≥–ª—Ç–æ–Ω-–æ—á–µ—Ä–µ–¥—å (—É–¥–æ–±–Ω–æ –¥–µ—Ä–≥–∞—Ç—å –∏–∑ GUI)
# -------------------------------------------------------
_queue_singleton: Optional[QueueDownloader] = None

def get_queue(out_dir: str, concurrency: int = 2, status_cb=None) -> QueueDownloader:
    """
    –ü–æ–ª—É—á–∏—Ç—å (–∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å) –≥–ª–æ–±–∞–ª—å–Ω—É—é –æ—á–µ—Ä–µ–¥—å –∑–∞–≥—Ä—É–∑–æ–∫.
    –ü—Ä–∏–º–µ—Ä:
        q = get_queue("Downloads", concurrency=2, status_cb=print)
        q.add("https://kino.pub/item/view/12345/...")
        q.add("https://kino.pub/item/view/67890/...")
        # –º–æ–∂–Ω–æ –¥–æ–∫–∏–¥—ã–≤–∞—Ç—å –µ—â—ë ‚Äî –ø–æ —Ö–æ–¥—É
    """
    global _queue_singleton
    if _queue_singleton is None:
        _queue_singleton = QueueDownloader(out_dir=out_dir, concurrency=concurrency, status_cb=status_cb)
    return _queue_singleton
